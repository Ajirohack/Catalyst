# CATALYST BACKEND CONFIGURATION
# =============================================================================
# Environment configuration for development and testing

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================

# API Server Settings
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=true
ENVIRONMENT=development

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_FILE_ENABLED=true
LOG_FILE_PATH=logs/catalyst.log

# =============================================================================
# AI PROVIDER CONFIGURATION
# =============================================================================

# Default AI provider (openai, anthropic, local)
DEFAULT_AI_PROVIDER=openai

# OpenAI Configuration (Test keys - replace with real keys for production)
OPENAI_API_KEY=sk-test-key-for-development-only
OPENAI_MODEL=gpt-4
OPENAI_MAX_TOKENS=4000
OPENAI_TEMPERATURE=0.7

# Anthropic Configuration (Test keys - replace with real keys for production)
ANTHROPIC_API_KEY=sk-ant-test-key-for-development-only
ANTHROPIC_MODEL=claude-3-sonnet-20240229
ANTHROPIC_MAX_TOKENS=4000

# Google AI (Gemini) Configuration
GOOGLE_AI_API_KEY=AIzaSyBrDatzs_m4rYQF-kH1AiyXSScp5s7VK_I
GOOGLE_AI_MODEL=gemini-2.0-flash
GOOGLE_AI_BASE_URL=https://generativelanguage.googleapis.com/v1beta

# Mistral AI Configuration
MISTRAL_API_KEY=your-mistral-api-key-here
MISTRAL_MODEL=mistral-large-latest
MISTRAL_BASE_URL=https://api.mistral.ai/v1

# Deepseek Configuration
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_MODEL=deepseek-chat
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1

# OpenRouter Configuration
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_MODEL=openai/gpt-3.5-turbo
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
OPENROUTER_APP_NAME=Catalyst AI Platform
OPENROUTER_APP_URL=https://github.com/catalyst-ai/backend

# Groq Configuration
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=mixtral-8x7b-32768
GROQ_BASE_URL=https://api.groq.com/openai/v1

# HuggingFace Configuration
HUGGINGFACE_API_KEY=your_huggingface_token_here
HUGGINGFACE_MODEL=google/gemma-7b-it
HUGGINGFACE_BASE_URL=https://api-inference.huggingface.co

# Local Models Configuration (Ollama)
LOCAL_AI_BASE_URL=http://localhost:11434
LOCAL_AI_ENABLED=false
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=tinydolphin:latest

# =============================================================================
# AI SYSTEM SETTINGS
# =============================================================================

# Enable fallback to other providers if primary fails
AI_FALLBACK_ENABLED=true

# Enable cost tracking and analytics
AI_COST_TRACKING_ENABLED=true
AI_USAGE_ANALYTICS_ENABLED=true

# Rate limiting (requests per hour)
AI_GLOBAL_RATE_LIMIT=1000

# Request timeout (seconds)
AI_REQUEST_TIMEOUT=30

# Maximum retry attempts
AI_MAX_RETRIES=3

# Quality settings
AI_MIN_CONFIDENCE_THRESHOLD=0.7

# Response caching
AI_RESPONSE_CACHING=true
AI_CACHE_TTL=3600

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# SQLite for development/testing
DATABASE_URL=sqlite:///./catalyst.db

# Database Pool Settings
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20
DB_POOL_TIMEOUT=30
DB_POOL_RECYCLE=3600

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

# JWT Configuration
JWT_SECRET_KEY=dev-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7

# CORS Settings
CORS_ORIGINS=["http://localhost:3000", "http://localhost:8080", "http://127.0.0.1:3000"]
CORS_ALLOW_CREDENTIALS=true
CORS_ALLOW_METHODS=["GET", "POST", "PUT", "DELETE", "OPTIONS"]
CORS_ALLOW_HEADERS=["*"]

# =============================================================================
# KNOWLEDGE BASE CONFIGURATION
# =============================================================================

# Vector Database Settings
VECTOR_DB_TYPE=chroma
VECTOR_DB_PATH=./data/vector_db
VECTOR_EMBEDDING_MODEL=text-embedding-ada-002
VECTOR_CHUNK_SIZE=1000
VECTOR_CHUNK_OVERLAP=200

# File Storage
FILE_STORAGE_PATH=./data/knowledge_base
MAX_FILE_SIZE_MB=100
ALLOWED_FILE_TYPES=["pdf", "txt", "docx", "md"]

# =============================================================================
# TESTING CONFIGURATION
# =============================================================================

# Test Database
TEST_DATABASE_URL=sqlite:///./test_catalyst.db

# Test AI Provider (Mock for testing)
TEST_AI_PROVIDER=mock
TEST_OPENAI_API_KEY=test-key
TEST_ANTHROPIC_API_KEY=test-key

# =============================================================================
# PERFORMANCE CONFIGURATION
# =============================================================================

# Async Settings
MAX_CONCURRENT_REQUESTS=100
REQUEST_TIMEOUT=30

# Cache Settings
CACHE_ENABLED=true
CACHE_TTL=3600
CACHE_MAX_SIZE=1000

# =============================================================================
# MONITORING AND ANALYTICS
# =============================================================================

# Metrics Collection
METRICS_ENABLED=true
METRICS_ENDPOINT=/metrics

# Health Check
HEALTH_CHECK_ENABLED=true
HEALTH_CHECK_ENDPOINT=/health

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================

# Auto-reload for development
RELOAD=true

# Debug mode
DEBUG_MODE=true

# Verbose logging
VERBOSE_LOGGING=true
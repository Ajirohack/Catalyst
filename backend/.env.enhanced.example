# Enhanced AI Configuration for Catalyst
# Add these settings to your .env file to enable advanced AI features

# =============================================================================
# AI PROVIDER CONFIGURATION
# =============================================================================

# Default AI provider (openai, anthropic, local)
DEFAULT_AI_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic Configuration  
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Local Models Configuration (Ollama)
LOCAL_AI_BASE_URL=http://localhost:11434
LOCAL_AI_ENABLED=false

# =============================================================================
# AI SYSTEM SETTINGS
# =============================================================================

# Enable fallback to other providers if primary fails
AI_FALLBACK_ENABLED=true

# Enable cost tracking and analytics
AI_COST_TRACKING_ENABLED=true
AI_USAGE_ANALYTICS_ENABLED=true

# Rate limiting (requests per hour)
AI_GLOBAL_RATE_LIMIT=1000

# Request timeout (seconds)
AI_REQUEST_TIMEOUT=30

# Maximum retry attempts
AI_MAX_RETRIES=3

# Quality settings
AI_MIN_CONFIDENCE_THRESHOLD=0.7

# Response caching
AI_RESPONSE_CACHING=true
AI_CACHE_TTL=3600

# =============================================================================
# PERFORMANCE TUNING
# =============================================================================

# Enable debug logging for AI requests
AI_DEBUG=false

# Maximum concurrent AI requests
AI_MAX_CONCURRENT_REQUESTS=10

# Default model preferences
OPENAI_DEFAULT_MODEL=gpt-3.5-turbo
ANTHROPIC_DEFAULT_MODEL=claude-3-sonnet-20240229
LOCAL_DEFAULT_MODEL=llama2

# =============================================================================
# EXISTING CATALYST CONFIGURATION
# =============================================================================

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=true

# Database (if using external DB)
DATABASE_URL=sqlite:///./catalyst.db

# Security
SECRET_KEY=your_secret_key_here
ALLOWED_ORIGINS=http://localhost:3000,chrome-extension://*

# Logging
LOG_LEVEL=INFO

# =============================================================================
# QUICK SETUP GUIDE
# =============================================================================

# 1. Copy this file to .env in your backend directory
# 2. Replace placeholder values with your actual API keys
# 3. Choose your default AI provider
# 4. Restart your backend server
# 5. Run test: python test_llm_router.py

# For OpenAI: Get API key from https://platform.openai.com/api-keys
# For Anthropic: Get API key from https://console.anthropic.com/
# For Local models: Install Ollama from https://ollama.ai/
